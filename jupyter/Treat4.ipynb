{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three classes for  data/TK.csv GB\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() takes from 2 to 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b9c223aae7a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;31m### Start\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m     \u001b[0mmytreat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTreat4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;31m# Overfit test i.e. run model on train data / else test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-b9c223aae7a0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, ifile, fit, model)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmyfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mofile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mofile\u001b[0m \u001b[0;31m# base for all other filenames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"ifile {self.ifile}, model {model}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() takes from 2 to 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "#!/home/admin/anaconda3/bin/python3\n",
    "#   author:martinmhan@yahoo.com date:  21/06/2020\n",
    "#   Copyright (C) <2020>  <Martin Mohan>\n",
    "#\n",
    "#   This program is free software; you can redistribute it and/or modify\n",
    "#   it under the terms of the GNU General Public License as published by\n",
    "#   the Free Software Foundation; either version 3 of the License, or\n",
    "#   (at your option) any later version.\n",
    "#\n",
    "#   This program is distributed in the hope that it will be useful,\n",
    "#   but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "#   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "#   GNU General Public License for more details.\n",
    "#\n",
    "#   You should have received a copy of the GNU General Public License\n",
    "#   along with this program; if not, write to the Free Software Foundation,\n",
    "#   Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301  USA\n",
    "#print(__doc__)\n",
    "#import joblib,argparse,re,sys,glob,os,time\n",
    "import argparse,re,sys,glob,os,time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from itertools import cycle\n",
    "import json\n",
    "import mmutils,myfit\n",
    "import rpt2tex\n",
    "import mmodels\n",
    "\n",
    "class Treat4():\n",
    "    \"\"\" Given input file and model name select the correct classifier.\n",
    "    Compare results roc,cm,metrics with train/test split of data.\n",
    "    Run trained model against TCE file to predict new planets.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self,ifile,fit,model):\n",
    "        \"\"\" Given input file and model name select the correct classifier.\n",
    "        Compare results roc,cm,metrics with train/test split of data.\n",
    "        Run trained model against TCE file to predict new planets.\n",
    "\n",
    "        \"\"\"\n",
    "        bTK=False\n",
    "        if(\"data/bT\" in ifile):\n",
    "            bTK=True\n",
    "            print(f'{ifile} contains data/b bTK = {bTK}')\n",
    "            if (not model.startswith(\"b\")):\n",
    "                print(f'Warn binary class model name recommended \"b\" not {model}')\n",
    "            else:\n",
    "                print(f'Binary class {ifile} and {model}')\n",
    "        else:\n",
    "            print(f'Three classes for  {ifile} {model}')\n",
    "        self.bTK=bTK\n",
    "        self.ifile=ifile\n",
    "        self.model=model\n",
    "        self.myfit=myfit.myfit(self.ifile,fit,model)\n",
    "        self.ofile=self.myfit.ofile # base for all other filenames\n",
    "        print(f\"ifile {self.ifile}, model {model}\")\n",
    "        self.clf=self.myfit.clf\n",
    "#        self.save_clf() # Saves classifier in file as verbatim tex\n",
    "\n",
    "    def save_clf(self):    \n",
    "        a=mmodels.mmodels(argv.model)\n",
    "        output=\"\\\\begin{verbatim}\\n\\\n",
    "        %s\\n\\\n",
    "        \\\\end{verbatim}\" %(a.clf)\n",
    "        ftex=self.ofile+\"_clf.tex\"\n",
    "        with open(ftex,'w') as f: f.write(output)\n",
    "        print(f\"Saved Clf in {ftex}\")\n",
    "\n",
    "    def get_plnt_num(self,kepname):\n",
    "        \"\"\" Called by getKepid to extract plnt_num from kepoi_name\n",
    "            e.g. Extract K00082.01 -> ['1']\n",
    "\n",
    "        \"\"\"\n",
    "        x=re.findall(r'\\d$', kepname) # K00001.01 -> ['1']\n",
    "        y=list(map(int, x)) # ['1'] -> 1 doesn't work?\n",
    "        return int(y[0])\n",
    "    \n",
    "    # Merge data/KOI.csv and data/TCE.csv to data/TK.csv\n",
    "    def getKepid(self,pfile,koi1):\n",
    "        \"\"\" Generate Kepid. The KOI table contains kepid and kepoi_name (e.g. K00082.01)\n",
    "        The TCE contains kepid and tce_plnt_num. This joins tables on kepid, tce_plnt_numb\n",
    "\n",
    "        \"\"\"\n",
    "        for index, row in koi1.iterrows():\n",
    "            koi1.loc[index,'tce_plnt_num'] = self.get_plnt_num(row['kepoi_name'])\n",
    "        koi1.tce_plnt_num = koi1.tce_plnt_num.astype(int) # ['1.0'] -> ['1']\n",
    "        df=koi1.merge(pfile, indicator=True, how='outer')\n",
    "        df=df.drop(['_merge'], axis=1)\n",
    "        return df\n",
    "\n",
    "    def crefFile(self): # combine results for cross reference\n",
    "        \"\"\" Join the input and the prediction file using Kepid and tce_plnt_num \n",
    "        Then generate precdictions and store with cross referenced results\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        ifilepred=self.ifile.replace(\"TK\", \"TCE1\") # Prediction file must already exist and have same extensions as TK... TCE1_...\n",
    "        df=pd.read_csv(self.ifile,comment=\"#\")  # Reference file with DV\n",
    "        df = df[['kepid','tce_plnt_num','kepoi_name','koi_disposition']].copy()\n",
    "        ######################################################\n",
    "        dfp=pd.read_csv(ifilepred,comment='#')\n",
    "        X_pred=dfp.drop(['kepid'], axis=1).to_numpy()\n",
    "        # Predict\n",
    "        dfp1=pd.DataFrame(self.clf.predict_proba(X_pred), columns=self.clf.classes_) # clf.classes maintained order FP,CONF,CAND\n",
    "        dfp1['y_pred']=self.clf.predict(X_pred)\n",
    "        dfp1['kepid'] = dfp.kepid.astype(int)\n",
    "        dfp1['tce_plnt_num']=dfp.tce_plnt_num.astype(int)\n",
    "        #########################################################\n",
    "        dfm=self.getKepid(dfp1,df)\n",
    "        \n",
    "        cref=self.ofile+\"_cref.csv\"\n",
    "        dfm.to_csv(cref,index=False)\n",
    "        print(f\"Saved {cref}\")\n",
    "        return cref\n",
    "\n",
    "    def plot_roc(self,df,force):\n",
    "        \"\"\" Plot the ROC. If ifile and model begin with b it is binary not multiclass. \"\"\"\n",
    "        if self.bTK:\n",
    "            style = {\"CONFIRMED\": \"green\",\"FALSE POSITIVE\": \"red\"}\n",
    "        else:\n",
    "            style = {\"CONFIRMED\": \"green\",\"CANDIDATE\": \"darkorange\",\"FALSE POSITIVE\": \"red\"}\n",
    "    \n",
    "        plt.rcParams.update({'axes.labelsize': 'x-large'})\n",
    "        fpr = dict();tpr = dict();roc_auc=dict();lw=2\n",
    "    \n",
    "        for i in style:\n",
    "            #    fpr[i], tpr[i],_ =roc_curve(y_test, df[i], pos_label=i)\n",
    "            fpr[i], tpr[i],_ =roc_curve(df['y_test'], df[i], pos_label=i)\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            plt.plot(fpr[i], tpr[i],color=style[i], lw=lw,\\\n",
    "                    label='AUC: {0} vs REST (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    \n",
    "            #y_score = clf.decision_function(X_test)\n",
    "        # Plot ROC curve\n",
    "        plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate or (1 - Specificity)')\n",
    "        plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "        plt.title('Receiver Operating Characteristic')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        rocfile=self.ofile+'_roc.pdf'\n",
    "        mmutils.write2plt(plt,rocfile,force)\n",
    "        return rocfile\n",
    "\n",
    "    def plot_cm(self,force):\n",
    "        \"\"\" Plot the Confusion Matrix \"\"\"\n",
    "        # Confusion Matrix\n",
    "        cm = pd.crosstab(df.y_test, df.y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "        print(cm)\n",
    "            #cm = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "        fig, (ax) = plt.subplots(1)\n",
    "        sns.heatmap(cm,annot=True,cmap='Blues', fmt='g')\n",
    "    \n",
    "        # labels, title and ticks\n",
    "        ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels');\n",
    "        ax.set_title('Confusion Matrix');\n",
    "        if self.bTK:\n",
    "            ax.xaxis.set_ticklabels(['CONFIRMED', 'FALSE POSITIVE']);\n",
    "        else:\n",
    "            ax.xaxis.set_ticklabels(['CANDIDATE','CONFIRMED', 'FALSE POSITIVE']);\n",
    "        cmfile=self.ofile+'_cm.pdf'\n",
    "        mmutils.write2plt(plt,cmfile,force)\n",
    "        return cmfile\n",
    "    \n",
    "    def metric_csv(self,df,caption,force):\n",
    "        \" Generate latex reprot with roc,cm and metrics\"\"\"\n",
    "        print(sklearn.metrics.classification_report(df.y_test, df.y_pred))\n",
    "        report=sklearn.metrics.classification_report(df.y_test, df.y_pred,output_dict=True)\n",
    "        report = pd.DataFrame(report).transpose()\n",
    "        rptfile=self.ofile+\"_rpt.csv\"\n",
    "        mmutils.write2csv(report,rptfile,force)\n",
    "        return rptfile\n",
    "\n",
    "\n",
    "    def div(self,x, y):\n",
    "        \"\"\" If divsion by zero return 0 \"\"\"\n",
    "        return 0 if y == 0 else (x / y)*100\n",
    "\n",
    "    def plot_cref(self,creffile):\n",
    "        \"\"\"Load and examine cross reference file with predictions. Generate bar plots of CONFIRMED vs Predicted \"\"\"\n",
    "        # Get Results\n",
    "        myclass='CONFIRMED'\n",
    "        df=pd.read_csv(creffile,comment='#')\n",
    "        totCONFIRMED=df.loc[(df['koi_disposition'] == 'CONFIRMED')]\n",
    "        totFP=df.loc[(df['koi_disposition'] == 'FALSE POSITIVE')]\n",
    "        totCAND=df.loc[(df['koi_disposition'] == 'CANDIDATE')]\n",
    "        totUN=df.loc[(df['koi_disposition'].isnull() ) ]\n",
    "    \n",
    "# recovered\n",
    "        rCONFIRMED=df.loc[(df['y_pred'] ==  'CONFIRMED') & (df['koi_disposition'] ==  'CONFIRMED')]                                        \n",
    "        rFP=df.loc[(df['y_pred'] == 'FP') & (df['koi_disposition'] ==  'CONFIRMED')]\n",
    "        rCAND=df.loc[(df['y_pred'] == 'CANDIDATE') & (df['koi_disposition'] ==  'CONFIRMED')]\n",
    "        rUN=df.loc[(df['y_pred'] == 'CONFIRMED') & (df['koi_disposition'].isnull() )]\n",
    "\n",
    "\n",
    "        df = pd.DataFrame([[rCONFIRMED.shape[0],totCONFIRMED.shape[0], self.div(rCONFIRMED.shape[0],totCONFIRMED.shape[0])],\\\n",
    "                       [rFP.shape[0],totFP.shape[0], self.div(rFP.shape[0],totFP.shape[0])],\\\n",
    "                       [rCAND.shape[0],totCAND.shape[0], self.div(rCAND.shape[0],totCAND.shape[0])],\\\n",
    "                       [rUN.shape[0],totUN.shape[0], self.div(rUN.shape[0],totUN.shape[0])]],\\\n",
    "         index=['CONFIRMED','FALSE POSITIVE','CANDIDATE','TCE1'],\n",
    "         columns=['recovered','total','Percentage'])\n",
    "\n",
    "        # PLOT\n",
    "        fig, axs = plt.subplots(2,2,sharex='col', sharey='row')\n",
    "        title=\"Planets predicted as CONFIRMED\"\n",
    "    #    title=mmutils.models()[model].split(\".\")[-1] # 'sklearn.ensemble.GradientBoostingClassifier'\n",
    "    \n",
    "        bins=50\n",
    "        dfy=rCONFIRMED\n",
    "        axs[0,0].hist(dfy[myclass], bins=bins,color='green')\n",
    "        pcnt=\" (\"+str(round(df.loc['CONFIRMED','Percentage'], 2))+\"%)\"\n",
    "        axs[0,0].set_title( 'CONFIRMED '+ str(dfy.shape[0])+\" / \"+str(totCONFIRMED.shape[0]) + pcnt)\n",
    "        axs[0,0].set_ylabel('Nr of Planets')\n",
    "\n",
    "        dfy=rUN\n",
    "        axs[0,1].hist(dfy[myclass], bins=bins,color='grey')\n",
    "        pcnt=\" (\"+str(round(df.loc['TCE1','Percentage'], 2))+\"%)\"\n",
    "        axs[0,1].set_title(\"TCE1 \"+ str(dfy.shape[0])  + \" / \"+ str(totUN.shape[0])  + pcnt)\n",
    "\n",
    "        dfy=rCAND\n",
    "        axs[1,0].hist(dfy[myclass], bins=bins,color='darkorange')\n",
    "        pcnt=\" (\"+str(round(df.loc['CANDIDATE','Percentage'], 2))+\"%)\"\n",
    "        axs[1,0].set_title( 'CANDIDATE '+  str(dfy.shape[0])+\" / \"+  str(totCAND.shape[0])  + pcnt)\n",
    "        axs[1,0].set_ylabel('Nr of Planets')\n",
    "        axs[1,0].set(xlabel='Probability Score')\n",
    "    \n",
    "        dfy=rFP\n",
    "        axs[1,1].hist(dfy[myclass], bins=bins,color='red')\n",
    "        pcnt=\" (\"+str(round(df.loc['FALSE POSITIVE','Percentage'], 2))+\"%)\"\n",
    "        axs[1,1].set_title(\"FALSE POSITIVE \"+ str(dfy.shape[0]) +\" / \"+ str(totFP.shape[0])  + pcnt)\n",
    "        axs[1,1].set(xlabel='Probability Score')\n",
    "\n",
    "        for ax in axs.flat:\n",
    "            ax.set_ylim(0,100)\n",
    "            ax.set_xlim(0.3,1)\n",
    "\n",
    "        # Create files for latex\n",
    "        rptfile=creffile.replace(\".csv\",\"_rpt.csv\")\n",
    "#        df.to_csv(rptfile,index=False)\n",
    "#        print(f\"saved {rptfile}\")\n",
    "\n",
    "        myplot=rptfile.replace(\"rpt.csv\",'CONFIRMED.pdf')\n",
    "        plt.savefig(myplot)\n",
    "        print(f\"Saved {myplot}\")\n",
    "        return myplot\n",
    "\n",
    "#        myrpt=rpt2tex.rpt2tex(rptfile) \n",
    "#        output=myrpt.creftex(argv.caption)\n",
    "#        return output\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Run model and generate report files  _roc.pdf, _cm.pdf, _report.csv, _tex ',formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "\n",
    "    parser.add_argument( \"--ifile\", type=str, default=\"data/TK.csv\",\n",
    "            help=\"input file: train_test_split will be run on this file (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument( \"--model\", type=str, default=\"GB\",\n",
    "            help=\"Model to test (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument(\"--overfit\", action=\"store_true\",\n",
    "            help=\"overfit test: Use train data to predict outcome and compare against test - ofile will have name _overfit_ \")\n",
    "\n",
    "    parser.add_argument(\"--fit\", action=\"store_true\",\n",
    "            help=\"fit model - otherwise load model from .pickle\")\n",
    "\n",
    "    parser.add_argument(\"--force\", action=\"store_true\",\n",
    "            help=\"force overwrite of results\")\n",
    "\n",
    "    parser.add_argument( \"--caption\", type=str, default=\"\",\n",
    "            help=\"Caption to add to eventual tex file (must be latex friendly) (default: %(default)s)\")\n",
    "\n",
    "    parser.add_argument(\"--showmodels\", action=\"store_true\",\n",
    "            help=\"Show all models and exit\")\n",
    "\n",
    "#    argv=parser.parse_args()\n",
    "        # argv=parser.parse_args()\n",
    "    \n",
    "    class Args:\n",
    "        ifile = 'data/TK.csv'\n",
    "        model = \"GB\"\n",
    "        fit = False\n",
    "        force = False\n",
    "        caption = \"\"\n",
    "        showmodels=False\n",
    "    argv=Args()\n",
    "\n",
    "    if argv.showmodels:\n",
    "        mymodel=mmodels.mmodels(\"GB\").desc\n",
    "        print(json.dumps(mymodel, indent=4, ensure_ascii=False))\n",
    "        sys.exit(0)\n",
    "\n",
    "### Start\n",
    "    mytreat=Treat4(argv.ifile,argv.fit,argv.model)\n",
    "\n",
    "    # Overfit test i.e. run model on train data / else test data\n",
    "    if argv.overfit:\n",
    "        mytreat.ofile=mytreat.ofile+\"_overfit\"\n",
    "        df=mytreat.myfit.overfit_results()\n",
    "    else:\n",
    "        df=mytreat.myfit.predict_results()\n",
    "\n",
    "# Generate graph from results show prediction accuracy\n",
    "    froc=mytreat.plot_roc(df,argv.force)\n",
    "    fcm=mytreat.plot_cm(argv.force)\n",
    "    fcsv=mytreat.metric_csv(df,argv.caption,argv.force)\n",
    "    caption=argv.caption\n",
    "\n",
    "# Run model on prediction file to check recovery and find new planets\n",
    "    cref=mytreat.crefFile() # Run model on prediction file\n",
    "    fcref=mytreat.plot_cref(cref)\n",
    "    myrpt=rpt2tex.rpt2tex(froc)\n",
    "\n",
    "    modelname=argv.model.replace(\"_\",\"\")\n",
    "    if argv.overfit:\n",
    "        caption=f\"{modelname}: overfit check \"\n",
    "        caption=f\"{modelname}: Overfit check (train data). ROC Curve, Confusion Matrix\"\n",
    "        output=myrpt.p2(froc,fcm,caption)\n",
    "    else:\n",
    "        caption=f\"{modelname}: ROC Curve, Confusion Matrix, Predicted CONFIRMED Recovery and Metrics\"\n",
    "        output=myrpt.p3c1(froc,fcm,fcref,fcsv,caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
